{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXR7eLP_Z8cm",
        "outputId": "096ec5a0-1def-45af-8624-2149364795fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROtkbZYDaFpp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqRd3WI_aJqs"
      },
      "outputs": [],
      "source": [
        "# load brain_extraction data\n",
        "X_Guys = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/X_Guys.npy')\n",
        "y_Guys = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/y_Guys.npy')\n",
        "ids_Guys = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/ids_Guys.npy')\n",
        "X_HH = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/X_HH.npy')\n",
        "y_HH = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/y_HH.npy')\n",
        "ids_HH = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/ids_HH.npy')\n",
        "X_IOP = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/X_IOP.npy')\n",
        "y_IOP = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/y_IOP.npy')\n",
        "ids_IOP = np.load('/content/drive/MyDrive/dhl_exam/data/brain_extraction/ids_IOP.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr-0sC1TaN4P"
      },
      "outputs": [],
      "source": [
        "#center data\n",
        "def centring(X):\n",
        "    X=np.asarray(X)\n",
        "    epsilon = 1e-7 \n",
        "    mean = np.mean(X, axis=0, keepdims=True)\n",
        "    std = np.std(X, axis=0, keepdims=True)\n",
        "    centered_array = (X - mean) / (std+epsilon)\n",
        "    return centered_array\n",
        "\n",
        "X_Guys_centered=centring(X_Guys)\n",
        "X_HH_centered=centring(X_HH)\n",
        "X_IOP_centered=centring(X_IOP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z4bbf2zaQrY",
        "outputId": "35156006-6c83-45d5-862f-cf87ea7548ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial shapes\n",
            "(317, 40, 128, 128)\n",
            "(317, 40, 128, 128)\n",
            "(317,)\n",
            "(176, 40, 128, 128)\n",
            "(176, 40, 128, 128)\n",
            "(176,)\n",
            "(71, 40, 128, 128)\n",
            "(71, 40, 128, 128)\n",
            "(71,)\n",
            "Check after split\n",
            "torch.Size([419, 40, 128, 128])\n",
            "torch.Size([419, 40, 128, 128])\n",
            "torch.Size([74, 40, 128, 128])\n",
            "torch.Size([74, 40, 128, 128])\n",
            "torch.Size([71, 40, 128, 128])\n",
            "torch.Size([71, 40, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "# producing required train / val / test split\n",
        "print(\"initial shapes\")\n",
        "print(X_Guys.shape)\n",
        "print(y_Guys.shape)\n",
        "print(ids_Guys.shape)\n",
        "print(X_HH.shape)\n",
        "print(y_HH.shape)\n",
        "print(ids_HH.shape)\n",
        "print(X_IOP.shape)\n",
        "print(y_IOP.shape)\n",
        "print(ids_IOP.shape)\n",
        "\n",
        "combined_Guys_HH_X = np.concatenate([X_Guys_centered, X_HH_centered], axis=0)\n",
        "combined_Guys_HH_y = np.concatenate([y_Guys, y_HH], axis=0)\n",
        "\n",
        "X_train = torch.Tensor(combined_Guys_HH_X[0:int(len(combined_Guys_HH_X)*0.85)])\n",
        "y_train = torch.Tensor(combined_Guys_HH_y[0:int(len(combined_Guys_HH_y)*0.85)])\n",
        "\n",
        "# val data 15%\n",
        "X_val = torch.Tensor(combined_Guys_HH_X[int(len(combined_Guys_HH_X)*0.85):int(len(combined_Guys_HH_X))])\n",
        "y_val = torch.Tensor(combined_Guys_HH_y[int(len(combined_Guys_HH_y)*0.85):int(len(combined_Guys_HH_y))])\n",
        "#test data from IOP data\n",
        "X_test =  torch.Tensor(X_IOP_centered[0:int(len(X_IOP_centered))])\n",
        "y_test = torch.Tensor(y_IOP[0:int(len(y_IOP))])\n",
        "\n",
        "print(\"Check after split\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EznIRhZlaVEo",
        "outputId": "3d929675-5d4a-4193-bd96-228afc437db3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check shapes after slicing into 2D\n",
            "torch.Size([419, 1, 128, 128])\n",
            "torch.Size([419, 1, 128, 128])\n",
            "torch.Size([74, 1, 128, 128])\n",
            "torch.Size([74, 1, 128, 128])\n",
            "torch.Size([71, 1, 128, 128])\n",
            "torch.Size([71, 1, 128, 128])\n"
          ]
        }
      ],
      "source": [
        "#sample slices - just pick 1 slice from 40 so for training always \n",
        "X_train=X_train[:,10,:,:]\n",
        "X_val=X_val[:,20,:,:]\n",
        "X_test=X_test[:,30,:,:]\n",
        "y_train=y_train[:,10,:,:]\n",
        "y_val=y_val[:,20,:,:]\n",
        "y_test=y_test[:,30,:,:]\n",
        "\n",
        "#introduce channel\n",
        "X_train=torch.reshape(X_train,(len(X_train),1,128,128))\n",
        "X_val=torch.reshape(X_val,(len(X_val),1,128,128))\n",
        "X_test=torch.reshape(X_test,(len(X_test),1,128,128))\n",
        "y_train=torch.reshape(y_train,(len(y_train),1,128,128))\n",
        "y_val=torch.reshape(y_val,(len(y_val),1,128,128))\n",
        "y_test=torch.reshape(y_test,(len(y_test),1,128,128))\n",
        "\n",
        "\n",
        "print(\"Check shapes after slicing into 2D\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq_yYnPTaXbM",
        "outputId": "0ee405c4-7fe4-41da-8c1d-cdf7b6e8ef71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(419, 2, 128, 128)\n",
            "(74, 2, 128, 128)\n",
            "(71, 2, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "def to_one_hot(y, num_classes):\n",
        "    y = np.array(y, dtype='int')\n",
        "    one_hot = np.eye(num_classes)[y.flatten()]\n",
        "    return one_hot.reshape(y.shape[0], num_classes,y.shape[2],y.shape[3]).astype(float)\n",
        "\n",
        "y_train = to_one_hot(y_train, 2)\n",
        "y_val= to_one_hot(y_val, 2)\n",
        "y_test = to_one_hot(y_test, 2)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTLKvFtKaaJX"
      },
      "outputs": [],
      "source": [
        "X_train=np.asarray(X_train)\n",
        "X_val=np.asarray(X_val)\n",
        "X_test=np.asarray(X_test)\n",
        "\n",
        "class numpy_dataset(Dataset): \n",
        "    def __init__(self, data, target): \n",
        "        self.data =  torch.from_numpy(data)\n",
        "        self.target = torch.from_numpy(target)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "train_dataset = numpy_dataset(X_train, y_train)\n",
        "val_dataset = numpy_dataset(X_val, y_val)\n",
        "test_dataset = numpy_dataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, drop_last=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce7eXkWJazwZ"
      },
      "outputs": [],
      "source": [
        "# adapted from Kaggle\n",
        "def dice_coef_metric(pred, label):\n",
        "    intersection = 2.0 * (pred * label).sum()\n",
        "    union = pred.sum() + label.sum()\n",
        "    if pred.sum() == 0 and label.sum() == 0:\n",
        "        return 1.\n",
        "    return intersection / union\n",
        "\n",
        "def dice_coef_loss(pred, label):\n",
        "    smooth = 1.0\n",
        "    intersection = 2.0 * (pred * label).sum() + smooth\n",
        "    union = pred.sum() + label.sum() + smooth\n",
        "    return 1 - (intersection / union)\n",
        "\n",
        "def bce_dice_loss(pred, label):\n",
        "    dice_loss = dice_coef_loss(pred, label)\n",
        "    bce_loss = nn.BCELoss()(pred, label)\n",
        "    return dice_loss + bce_loss\n",
        "\n",
        "\n",
        "def tversky(y_pred,y_true, smooth=1, alpha=0.7):\n",
        "    y_true_pos = y_true.view(-1)\n",
        "    y_pred_pos = y_pred.view(-1)\n",
        "    true_pos = torch.sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = torch.sum(y_true_pos * (1 - y_pred_pos))\n",
        "    false_pos = torch.sum((1 - y_true_pos) * y_pred_pos)\n",
        "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
        "\n",
        "\n",
        "def tversky_loss(y_pred,y_true):\n",
        "    return 1 - tversky(y_true, y_pred)\n",
        "\n",
        "\n",
        "def focal_tversky_loss(y_pred,y_true, gamma=0.75):\n",
        "    tv = tversky(y_true, y_pred)\n",
        "    return torch.pow((1 - tv), gamma)\n",
        "\n",
        "\n",
        "def lovasz_softmax_flat(logits, labels):\n",
        "    probas = F.softmax(logits, dim=1)\n",
        "    labels = labels.float()\n",
        "\n",
        "    if probas.numel() == 0:\n",
        "        return logits * 0.0\n",
        "\n",
        "    signs = 2 * labels - 1\n",
        "    errors = (1 - probas * signs)\n",
        "    errors_sorted, perm = torch.sort(errors.reshape(-1), dim=0, descending=True)\n",
        "    perm = perm.cpu().numpy()\n",
        "    gt_sorted = labels.reshape(-1)[perm]\n",
        "    grad = lovasz_grad(gt_sorted)\n",
        "\n",
        "    loss = torch.dot(F.elu(errors_sorted) + 1, Variable(grad, requires_grad=False))\n",
        "    return loss\n",
        "\n",
        "def lovasz_grad(gt_sorted):\n",
        "\n",
        "    p = len(gt_sorted)\n",
        "    gts = gt_sorted.sum()\n",
        "    intersection = gts - gt_sorted.cumsum(0)\n",
        "    union = gts + (1 - gt_sorted).cumsum(0)\n",
        "    jaccard = 1.0 - intersection / union\n",
        "    if p > 1:  # cover cases where p == 0\n",
        "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Drq71mQx3y",
        "outputId": "640bd388-df8b-45d5-b764-f0419e00998e"
      },
      "outputs": [],
      "source": [
        "lf_train_loss_history={}\n",
        "lf_train_dice_history={}\n",
        "lf_val_loss_history={}\n",
        "lf_val_dice_history={}\n",
        "dict_pred_dice={}\n",
        "dict_stopping_epoch={}\n",
        "dict_time_taken={}\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "num_epochs = 100\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "lfs=[dice_coef_loss,bce_dice_loss,tversky_loss,focal_tversky_loss,lovasz_softmax_flat]\n",
        "\n",
        "for lf in lfs:\n",
        "  start_time = time.time()\n",
        "  model = UNet(n_channels=1, n_classes=2, bilinear=True).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
        "  train_loss_history, train_dice_history, val_loss_history, val_dice_history,se = train_model_early_stopping(train_dataloader, val_dataloader, lf, optimizer, scheduler, num_epochs)\n",
        "  end_time = time.time()\n",
        "  lf_train_loss_history[str(lf)]=train_loss_history\n",
        "  lf_train_dice_history[str(lf)]=train_dice_history\n",
        "  lf_val_loss_history[str(lf)]=val_loss_history\n",
        "  lf_val_dice_history[str(lf)]=val_dice_history\n",
        "  dict_pred_dice[str(lf)]=prediction_dice(model, test_dataloader)\n",
        "  dict_stopping_epoch[str(lf)]=se\n",
        "  dict_time_taken[str(lf)]=end_time - start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykC-zRL5cMlS"
      },
      "outputs": [],
      "source": [
        "def plot_dice_history(model_name, train_dice_history, val_dice_history, num_epochs):\n",
        "    \n",
        "    x = np.arange(num_epochs)\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, train_dice_history, label='Training DICE Score', lw=3)\n",
        "    plt.plot(x, val_dice_history, label='Validation DICE Score', lw=3)\n",
        "\n",
        "    plt.title(f\"{model_name}\", fontsize=20)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.xlabel(\"Epoch\", fontsize=15)\n",
        "    plt.ylabel(\"DICE score\", fontsize=15)\n",
        "\n",
        "    path='/content/drive/MyDrive/dhl_exam/figures/'+str(model_name)+\"-dice.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def plot_loss_history(model_name, train_loss_history, val_loss_history, num_epochs):\n",
        "    \n",
        "    x = np.arange(num_epochs)\n",
        "    fig = plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, train_loss_history, label='Training Loss', lw=3)\n",
        "    plt.plot(x, val_loss_history, label='Validation Loss', lw=3)\n",
        "\n",
        "    plt.title(f\"{model_name}\", fontsize=20)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.xlabel(\"Epoch\", fontsize=15)\n",
        "    plt.ylabel(\"Loss\", fontsize=15)\n",
        "    path='/content/drive/MyDrive/dhl_exam/figures/'+str(model_name)+\"-loss.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def prediction_dice(net, test_dataloader):\n",
        "    test_dice=0\n",
        "\n",
        "    with torch.no_grad():  # So no gradients accumulate\n",
        "        for batch_idx, (data, target) in enumerate(test_dataloader):\n",
        "          data = data.to(device).float()\n",
        "          target = target.to(device).float()\n",
        "           \n",
        "          pred = net(data)\n",
        "          out_cut = np.copy(pred.data.cpu().numpy())\n",
        "          out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "          out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "          dice = dice_coef_metric(out_cut, target.data.cpu().numpy())\n",
        "          test_dice += dice\n",
        "        mean_dice = test_dice / len(test_dataloader)\n",
        "        return mean_dice\n",
        "\n",
        "def predict(net, test_dataloader):\n",
        "    test_dice=0\n",
        "\n",
        "    with torch.no_grad():  # So no gradients accumulate\n",
        "        for batch_idx, (data, target) in enumerate(test_dataloader):\n",
        "          data = data.to(device).float()\n",
        "          target = target.to(device).float()\n",
        "           \n",
        "          pred = net(data)\n",
        "    return data.data.cpu().numpy(),target.data.cpu().numpy(),pred.data.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ35Lt9wbE2f"
      },
      "outputs": [],
      "source": [
        "def train_loop(model, loader, loss_func,optimizer):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    train_dices = []\n",
        "    \n",
        "#     \n",
        "    for i, (image, mask) in enumerate(loader):\n",
        "        image = image.to(device).float()\n",
        "        mask = mask.to(device).float()\n",
        "        outputs = model(image)\n",
        "        out_cut = np.copy(outputs.data.cpu().numpy())\n",
        "        out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "        out_cut[np.nonzero(out_cut >= 0.5)] = 1.0            \n",
        "\n",
        "        dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
        "        loss = loss_func(outputs, mask)\n",
        "        train_losses.append(loss.item())\n",
        "        train_dices.append(dice)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    return train_dices, train_losses\n",
        "\n",
        "def eval_loop(model, loader, loss_func, scheduler,training=True):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_dice = 0\n",
        "    with torch.no_grad():\n",
        "        for step, (image, mask) in enumerate(loader):\n",
        "            image = image.to(device).float()\n",
        "            mask = mask.to(device).float()\n",
        "    \n",
        "            outputs = model(image)\n",
        "            loss = loss_func(outputs, mask)\n",
        "            \n",
        "            out_cut = np.copy(outputs.data.cpu().numpy())\n",
        "            out_cut[np.nonzero(out_cut < 0.5)] = 0.0\n",
        "            out_cut[np.nonzero(out_cut >= 0.5)] = 1.0\n",
        "            dice = dice_coef_metric(out_cut, mask.data.cpu().numpy())\n",
        "            \n",
        "            val_loss += loss\n",
        "            val_dice += dice\n",
        "        \n",
        "        val_mean_dice = val_dice / len(loader)\n",
        "        val_mean_loss = val_loss / step\n",
        "        \n",
        "        if training:\n",
        "            scheduler.step(val_mean_dice)\n",
        "        \n",
        "    return val_mean_dice, val_mean_loss\n",
        "\n",
        "def train_model(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs):\n",
        "    train_loss_history = []\n",
        "    train_dice_history = []\n",
        "    val_loss_history = []\n",
        "    val_dice_history = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        train_dices, train_losses = train_loop(model, train_loader, loss_func,optimizer)\n",
        "        train_mean_dice = np.array(train_dices).mean()\n",
        "        train_mean_loss = np.array(train_losses).mean()\n",
        "        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func,scheduler)\n",
        "        \n",
        "        train_loss_history.append(np.array(train_losses).mean())\n",
        "        train_dice_history.append(np.array(train_dices).mean())\n",
        "        val_loss_history.append(val_mean_loss.cpu().numpy())\n",
        "        val_dice_history.append(val_mean_dice)\n",
        "        \n",
        "        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f}'.format(epoch+1, num_epochs,\n",
        "                                                                                                                 train_mean_loss,\n",
        "                                                                                                                 val_mean_loss,\n",
        "                                                                                                                 train_mean_dice,\n",
        "                                                                                                                 val_mean_dice))\n",
        "        \n",
        "\n",
        "    return train_loss_history, train_dice_history, val_loss_history, val_dice_history\n",
        "\n",
        "def train_model_early_stopping(train_loader, val_loader, loss_func, optimizer, scheduler, num_epochs, patience=5):\n",
        "    train_loss_history = []\n",
        "    train_dice_history = []\n",
        "    val_loss_history = []\n",
        "    val_dice_history = []\n",
        "\n",
        "    best_val_dice = 0\n",
        "    consecutive_no_improvement = 0\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        train_dices, train_losses = train_loop(model, train_loader, loss_func, optimizer)\n",
        "        train_mean_dice = np.array(train_dices).mean()\n",
        "        train_mean_loss = np.array(train_losses).mean()\n",
        "        val_mean_dice, val_mean_loss = eval_loop(model, val_loader, loss_func, scheduler)\n",
        "        \n",
        "        train_loss_history.append(train_mean_loss)\n",
        "        train_dice_history.append(train_mean_dice)\n",
        "        val_loss_history.append(val_mean_loss.cpu().numpy())\n",
        "        val_dice_history.append(val_mean_dice)\n",
        "        \n",
        "        print('Epoch: {}/{} |  Train Loss: {:.3f}, Val Loss: {:.3f}, Train DICE: {:.3f}, Val DICE: {:.3f}'.format(epoch+1, num_epochs,\n",
        "                                                                                                                 train_mean_loss,\n",
        "                                                                                                                 val_mean_loss,\n",
        "                                                                                                                 train_mean_dice,\n",
        "                                                                                                                 val_mean_dice))\n",
        "\n",
        "        if val_mean_dice > best_val_dice:\n",
        "            best_val_dice = val_mean_dice\n",
        "            consecutive_no_improvement = 0\n",
        "            print('Best validation dice coefficient improved to {:.3f}'.format(best_val_dice))\n",
        "        else:\n",
        "            consecutive_no_improvement += 1\n",
        "            print('No improvement in validation dice coefficient for {} consecutive epochs'.format(consecutive_no_improvement))\n",
        "            if consecutive_no_improvement >= patience:\n",
        "                print('Early stopping triggered after {} epochs'.format(epoch+1))\n",
        "                break\n",
        "\n",
        "    return train_loss_history, train_dice_history, val_loss_history, val_dice_history,epoch+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzaoOfb-chL3"
      },
      "outputs": [],
      "source": [
        "class FCN_flexible(nn.Module):\n",
        "    def __init__(self, input_shape=(1, 128, 128), num_classes=2, dropout_prob=0.5, num_layers=2):\n",
        "        super(FCN_flexible, self).__init__()\n",
        "\n",
        "       \n",
        "        encoder_layers = []\n",
        "        in_channels = input_shape[0]\n",
        "        for i in range(num_layers):\n",
        "            out_channels = 64 * (2 ** i)\n",
        "            encoder_layers.extend([\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout_prob),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "\n",
        "        \n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels * 2, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Conv2d(in_channels * 2, in_channels, kernel_size=1)\n",
        "        )\n",
        "\n",
        "       \n",
        "        decoder_layers = []\n",
        "        for i in range(num_layers - 1, -1, -1):\n",
        "            out_channels = 64 * (2 ** i)\n",
        "            decoder_layers.extend([\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout_prob)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "\n",
        "        decoder_layers.extend([\n",
        "            nn.Conv2d(out_channels, num_classes, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        ])\n",
        "\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.middle(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxN2gmysI5IJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv = conv_block(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(self.pool(x))\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.conv = conv_block(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat((skip, x), dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "        self.init_conv = conv_block(in_channels, 64)\n",
        "        self.encoders = nn.ModuleList([\n",
        "            Encoder(64, 128),\n",
        "            Encoder(128, 256),\n",
        "            Encoder(256, 512),\n",
        "            Encoder(512, 1024)\n",
        "        ])\n",
        "        self.decoders = nn.ModuleList([\n",
        "            Decoder(1024, 512),\n",
        "            Decoder(512, 256),\n",
        "            Decoder(256, 128),\n",
        "            Decoder(128, 64)\n",
        "        ])\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.init_conv(x)\n",
        "        skips = [x1]\n",
        "        for encoder in self.encoders:\n",
        "            skips.append(encoder(skips[-1]))\n",
        "\n",
        "        x = skips.pop()\n",
        "        for decoder in self.decoders:\n",
        "            x = decoder(x, skips.pop())\n",
        "\n",
        "        return self.final_conv(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I8NRdwQkKbeH",
        "outputId": "00c986e7-267a-4c1c-e746-95b076392455"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "alphas = [0.3, 0.5, 0.7]\n",
        "betas = [0.3, 0.5, 0.7]\n",
        "smooths = [1.0, 1.5, 2.0]\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# grid search experiment\n",
        "results = []\n",
        "for alpha, beta, smooth in itertools.product(alphas, betas, smooths):\n",
        "    print(f'Training TverskyLoss with alpha={alpha}, beta={beta}, smooth={smooth}...')\n",
        "    loss_func = TverskyLoss(alpha=alpha, beta=beta, smooth=smooth)\n",
        "    model = UNet(n_channels=1, n_classes=2, bilinear=True).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
        "    train_loss_history, train_dice_history, val_loss_history, val_dice_history, epochs = train_model_early_stopping(train_dataloader, val_dataloader, loss_func, optimizer, scheduler, num_epochs=50)\n",
        "    results.append((alpha, beta, smooth, epochs, max(val_dice_history)))\n",
        "\n",
        "\n",
        "print('\\nGrid Search Results:')\n",
        "for alpha, beta, smooth, epochs, val_dice in results:\n",
        "    print(f'alpha={alpha}, beta={beta}, smooth={smooth}, epochs={epochs}, val_dice={val_dice:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_jtbtDzGYT-",
        "outputId": "db28d8a5-9a76-4ac2-8769-a1b4c62691bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/50 |  Train Loss: 0.911, Val Loss: 1.207, Train DICE: 0.719, Val DICE: 0.872\n",
            "Best validation dice coefficient improved to 0.872\n",
            "Epoch: 2/50 |  Train Loss: 0.863, Val Loss: 1.140, Train DICE: 0.915, Val DICE: 0.914\n",
            "Best validation dice coefficient improved to 0.914\n",
            "Epoch: 3/50 |  Train Loss: 0.841, Val Loss: 1.129, Train DICE: 0.946, Val DICE: 0.928\n",
            "Best validation dice coefficient improved to 0.928\n",
            "Epoch: 4/50 |  Train Loss: 0.828, Val Loss: 1.109, Train DICE: 0.958, Val DICE: 0.943\n",
            "Best validation dice coefficient improved to 0.943\n",
            "Epoch: 5/50 |  Train Loss: 0.818, Val Loss: 1.100, Train DICE: 0.964, Val DICE: 0.946\n",
            "Best validation dice coefficient improved to 0.946\n",
            "Epoch: 6/50 |  Train Loss: 0.810, Val Loss: 1.094, Train DICE: 0.968, Val DICE: 0.943\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 7/50 |  Train Loss: 0.803, Val Loss: 1.082, Train DICE: 0.971, Val DICE: 0.950\n",
            "Best validation dice coefficient improved to 0.950\n",
            "Epoch: 8/50 |  Train Loss: 0.796, Val Loss: 1.073, Train DICE: 0.972, Val DICE: 0.955\n",
            "Best validation dice coefficient improved to 0.955\n",
            "Epoch: 9/50 |  Train Loss: 0.788, Val Loss: 1.065, Train DICE: 0.975, Val DICE: 0.957\n",
            "Best validation dice coefficient improved to 0.957\n",
            "Epoch: 10/50 |  Train Loss: 0.782, Val Loss: 1.066, Train DICE: 0.976, Val DICE: 0.949\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.776, Val Loss: 1.059, Train DICE: 0.977, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 12/50 |  Train Loss: 0.771, Val Loss: 1.048, Train DICE: 0.977, Val DICE: 0.957\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 13/50 |  Train Loss: 0.764, Val Loss: 1.044, Train DICE: 0.979, Val DICE: 0.956\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.758, Val Loss: 1.041, Train DICE: 0.982, Val DICE: 0.957\n",
            "Best validation dice coefficient improved to 0.957\n",
            "Epoch: 15/50 |  Train Loss: 0.756, Val Loss: 1.039, Train DICE: 0.983, Val DICE: 0.958\n",
            "Best validation dice coefficient improved to 0.958\n",
            "Epoch: 16/50 |  Train Loss: 0.755, Val Loss: 1.041, Train DICE: 0.984, Val DICE: 0.957\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 17/50 |  Train Loss: 0.754, Val Loss: 1.038, Train DICE: 0.984, Val DICE: 0.959\n",
            "Best validation dice coefficient improved to 0.959\n",
            "Epoch: 18/50 |  Train Loss: 0.753, Val Loss: 1.040, Train DICE: 0.985, Val DICE: 0.956\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 19/50 |  Train Loss: 0.753, Val Loss: 1.040, Train DICE: 0.985, Val DICE: 0.956\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 20/50 |  Train Loss: 0.752, Val Loss: 1.040, Train DICE: 0.985, Val DICE: 0.955\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 21/50 |  Train Loss: 0.751, Val Loss: 1.036, Train DICE: 0.985, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 22/50 |  Train Loss: 0.750, Val Loss: 1.036, Train DICE: 0.986, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 22 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.829, Val Loss: 1.091, Train DICE: 0.754, Val DICE: 0.889\n",
            "Best validation dice coefficient improved to 0.889\n",
            "Epoch: 2/50 |  Train Loss: 0.755, Val Loss: 0.985, Train DICE: 0.927, Val DICE: 0.927\n",
            "Best validation dice coefficient improved to 0.927\n",
            "Epoch: 3/50 |  Train Loss: 0.722, Val Loss: 0.964, Train DICE: 0.951, Val DICE: 0.945\n",
            "Best validation dice coefficient improved to 0.945\n",
            "Epoch: 4/50 |  Train Loss: 0.705, Val Loss: 0.947, Train DICE: 0.961, Val DICE: 0.948\n",
            "Best validation dice coefficient improved to 0.948\n",
            "Epoch: 5/50 |  Train Loss: 0.692, Val Loss: 0.933, Train DICE: 0.966, Val DICE: 0.947\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 6/50 |  Train Loss: 0.680, Val Loss: 0.922, Train DICE: 0.970, Val DICE: 0.948\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 7/50 |  Train Loss: 0.669, Val Loss: 0.906, Train DICE: 0.973, Val DICE: 0.952\n",
            "Best validation dice coefficient improved to 0.952\n",
            "Epoch: 8/50 |  Train Loss: 0.659, Val Loss: 0.898, Train DICE: 0.973, Val DICE: 0.952\n",
            "Best validation dice coefficient improved to 0.952\n",
            "Epoch: 9/50 |  Train Loss: 0.648, Val Loss: 0.895, Train DICE: 0.976, Val DICE: 0.946\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 10/50 |  Train Loss: 0.638, Val Loss: 0.878, Train DICE: 0.977, Val DICE: 0.951\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.630, Val Loss: 0.871, Train DICE: 0.977, Val DICE: 0.951\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 12/50 |  Train Loss: 0.620, Val Loss: 0.849, Train DICE: 0.979, Val DICE: 0.960\n",
            "Best validation dice coefficient improved to 0.960\n",
            "Epoch: 13/50 |  Train Loss: 0.610, Val Loss: 0.855, Train DICE: 0.980, Val DICE: 0.950\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.600, Val Loss: 0.833, Train DICE: 0.981, Val DICE: 0.959\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 15/50 |  Train Loss: 0.591, Val Loss: 0.823, Train DICE: 0.982, Val DICE: 0.959\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 16/50 |  Train Loss: 0.583, Val Loss: 0.827, Train DICE: 0.982, Val DICE: 0.952\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 17/50 |  Train Loss: 0.574, Val Loss: 0.817, Train DICE: 0.985, Val DICE: 0.957\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 17 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.745, Val Loss: 0.980, Train DICE: 0.773, Val DICE: 0.860\n",
            "Best validation dice coefficient improved to 0.860\n",
            "Epoch: 2/50 |  Train Loss: 0.652, Val Loss: 0.836, Train DICE: 0.921, Val DICE: 0.931\n",
            "Best validation dice coefficient improved to 0.931\n",
            "Epoch: 3/50 |  Train Loss: 0.615, Val Loss: 0.848, Train DICE: 0.946, Val DICE: 0.905\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 4/50 |  Train Loss: 0.596, Val Loss: 0.803, Train DICE: 0.956, Val DICE: 0.946\n",
            "Best validation dice coefficient improved to 0.946\n",
            "Epoch: 5/50 |  Train Loss: 0.578, Val Loss: 0.792, Train DICE: 0.966, Val DICE: 0.940\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 6/50 |  Train Loss: 0.565, Val Loss: 0.766, Train DICE: 0.967, Val DICE: 0.948\n",
            "Best validation dice coefficient improved to 0.948\n",
            "Epoch: 7/50 |  Train Loss: 0.551, Val Loss: 0.764, Train DICE: 0.971, Val DICE: 0.944\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 8/50 |  Train Loss: 0.538, Val Loss: 0.750, Train DICE: 0.974, Val DICE: 0.945\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 9/50 |  Train Loss: 0.527, Val Loss: 0.736, Train DICE: 0.975, Val DICE: 0.943\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 10/50 |  Train Loss: 0.515, Val Loss: 0.725, Train DICE: 0.976, Val DICE: 0.946\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.506, Val Loss: 0.715, Train DICE: 0.980, Val DICE: 0.952\n",
            "Best validation dice coefficient improved to 0.952\n",
            "Epoch: 12/50 |  Train Loss: 0.503, Val Loss: 0.711, Train DICE: 0.981, Val DICE: 0.953\n",
            "Best validation dice coefficient improved to 0.953\n",
            "Epoch: 13/50 |  Train Loss: 0.501, Val Loss: 0.711, Train DICE: 0.982, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.499, Val Loss: 0.708, Train DICE: 0.983, Val DICE: 0.954\n",
            "Best validation dice coefficient improved to 0.954\n",
            "Epoch: 15/50 |  Train Loss: 0.498, Val Loss: 0.709, Train DICE: 0.983, Val DICE: 0.952\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 16/50 |  Train Loss: 0.496, Val Loss: 0.710, Train DICE: 0.983, Val DICE: 0.950\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 17/50 |  Train Loss: 0.495, Val Loss: 0.707, Train DICE: 0.984, Val DICE: 0.952\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 18/50 |  Train Loss: 0.494, Val Loss: 0.706, Train DICE: 0.984, Val DICE: 0.952\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 19/50 |  Train Loss: 0.492, Val Loss: 0.705, Train DICE: 0.985, Val DICE: 0.952\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 19 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.684, Val Loss: 0.905, Train DICE: 0.733, Val DICE: 0.865\n",
            "Best validation dice coefficient improved to 0.865\n",
            "Epoch: 2/50 |  Train Loss: 0.553, Val Loss: 0.700, Train DICE: 0.916, Val DICE: 0.921\n",
            "Best validation dice coefficient improved to 0.921\n",
            "Epoch: 3/50 |  Train Loss: 0.501, Val Loss: 0.679, Train DICE: 0.946, Val DICE: 0.935\n",
            "Best validation dice coefficient improved to 0.935\n",
            "Epoch: 4/50 |  Train Loss: 0.474, Val Loss: 0.641, Train DICE: 0.959, Val DICE: 0.949\n",
            "Best validation dice coefficient improved to 0.949\n",
            "Epoch: 5/50 |  Train Loss: 0.456, Val Loss: 0.627, Train DICE: 0.964, Val DICE: 0.948\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 6/50 |  Train Loss: 0.440, Val Loss: 0.614, Train DICE: 0.968, Val DICE: 0.948\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 7/50 |  Train Loss: 0.425, Val Loss: 0.591, Train DICE: 0.972, Val DICE: 0.951\n",
            "Best validation dice coefficient improved to 0.951\n",
            "Epoch: 8/50 |  Train Loss: 0.413, Val Loss: 0.578, Train DICE: 0.973, Val DICE: 0.952\n",
            "Best validation dice coefficient improved to 0.952\n",
            "Epoch: 9/50 |  Train Loss: 0.399, Val Loss: 0.560, Train DICE: 0.976, Val DICE: 0.956\n",
            "Best validation dice coefficient improved to 0.956\n",
            "Epoch: 10/50 |  Train Loss: 0.387, Val Loss: 0.548, Train DICE: 0.977, Val DICE: 0.956\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.375, Val Loss: 0.544, Train DICE: 0.979, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 12/50 |  Train Loss: 0.366, Val Loss: 0.529, Train DICE: 0.979, Val DICE: 0.954\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 13/50 |  Train Loss: 0.356, Val Loss: 0.528, Train DICE: 0.979, Val DICE: 0.952\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.346, Val Loss: 0.513, Train DICE: 0.982, Val DICE: 0.958\n",
            "Best validation dice coefficient improved to 0.958\n",
            "Epoch: 15/50 |  Train Loss: 0.343, Val Loss: 0.510, Train DICE: 0.984, Val DICE: 0.959\n",
            "Best validation dice coefficient improved to 0.959\n",
            "Epoch: 16/50 |  Train Loss: 0.341, Val Loss: 0.508, Train DICE: 0.984, Val DICE: 0.959\n",
            "Best validation dice coefficient improved to 0.959\n",
            "Epoch: 17/50 |  Train Loss: 0.340, Val Loss: 0.507, Train DICE: 0.985, Val DICE: 0.959\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 18/50 |  Train Loss: 0.338, Val Loss: 0.508, Train DICE: 0.985, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 19/50 |  Train Loss: 0.336, Val Loss: 0.505, Train DICE: 0.986, Val DICE: 0.959\n",
            "Best validation dice coefficient improved to 0.959\n",
            "Epoch: 20/50 |  Train Loss: 0.335, Val Loss: 0.503, Train DICE: 0.986, Val DICE: 0.960\n",
            "Best validation dice coefficient improved to 0.960\n",
            "Epoch: 21/50 |  Train Loss: 0.334, Val Loss: 0.506, Train DICE: 0.986, Val DICE: 0.957\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 22/50 |  Train Loss: 0.333, Val Loss: 0.502, Train DICE: 0.986, Val DICE: 0.959\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 23/50 |  Train Loss: 0.331, Val Loss: 0.501, Train DICE: 0.987, Val DICE: 0.959\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 24/50 |  Train Loss: 0.331, Val Loss: 0.501, Train DICE: 0.986, Val DICE: 0.959\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 25/50 |  Train Loss: 0.329, Val Loss: 0.501, Train DICE: 0.987, Val DICE: 0.959\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 25 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.631, Val Loss: 0.813, Train DICE: 0.709, Val DICE: 0.858\n",
            "Best validation dice coefficient improved to 0.858\n",
            "Epoch: 2/50 |  Train Loss: 0.483, Val Loss: 0.608, Train DICE: 0.911, Val DICE: 0.924\n",
            "Best validation dice coefficient improved to 0.924\n",
            "Epoch: 3/50 |  Train Loss: 0.421, Val Loss: 0.582, Train DICE: 0.945, Val DICE: 0.927\n",
            "Best validation dice coefficient improved to 0.927\n",
            "Epoch: 4/50 |  Train Loss: 0.394, Val Loss: 0.542, Train DICE: 0.954, Val DICE: 0.940\n",
            "Best validation dice coefficient improved to 0.940\n",
            "Epoch: 5/50 |  Train Loss: 0.372, Val Loss: 0.525, Train DICE: 0.962, Val DICE: 0.933\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 6/50 |  Train Loss: 0.354, Val Loss: 0.502, Train DICE: 0.967, Val DICE: 0.945\n",
            "Best validation dice coefficient improved to 0.945\n",
            "Epoch: 7/50 |  Train Loss: 0.339, Val Loss: 0.492, Train DICE: 0.970, Val DICE: 0.944\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 8/50 |  Train Loss: 0.324, Val Loss: 0.469, Train DICE: 0.973, Val DICE: 0.947\n",
            "Best validation dice coefficient improved to 0.947\n",
            "Epoch: 9/50 |  Train Loss: 0.312, Val Loss: 0.450, Train DICE: 0.975, Val DICE: 0.952\n",
            "Best validation dice coefficient improved to 0.952\n",
            "Epoch: 10/50 |  Train Loss: 0.299, Val Loss: 0.442, Train DICE: 0.977, Val DICE: 0.951\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.289, Val Loss: 0.433, Train DICE: 0.978, Val DICE: 0.951\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 12/50 |  Train Loss: 0.278, Val Loss: 0.410, Train DICE: 0.980, Val DICE: 0.959\n",
            "Best validation dice coefficient improved to 0.959\n",
            "Epoch: 13/50 |  Train Loss: 0.268, Val Loss: 0.409, Train DICE: 0.980, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.260, Val Loss: 0.408, Train DICE: 0.981, Val DICE: 0.950\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 15/50 |  Train Loss: 0.253, Val Loss: 0.397, Train DICE: 0.981, Val DICE: 0.951\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 16/50 |  Train Loss: 0.244, Val Loss: 0.379, Train DICE: 0.982, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 17/50 |  Train Loss: 0.236, Val Loss: 0.373, Train DICE: 0.984, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 17 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.570, Val Loss: 0.747, Train DICE: 0.712, Val DICE: 0.853\n",
            "Best validation dice coefficient improved to 0.853\n",
            "Epoch: 2/50 |  Train Loss: 0.416, Val Loss: 0.522, Train DICE: 0.915, Val DICE: 0.920\n",
            "Best validation dice coefficient improved to 0.920\n",
            "Epoch: 3/50 |  Train Loss: 0.357, Val Loss: 0.478, Train DICE: 0.944, Val DICE: 0.940\n",
            "Best validation dice coefficient improved to 0.940\n",
            "Epoch: 4/50 |  Train Loss: 0.326, Val Loss: 0.464, Train DICE: 0.957, Val DICE: 0.934\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 5/50 |  Train Loss: 0.305, Val Loss: 0.445, Train DICE: 0.963, Val DICE: 0.934\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 6/50 |  Train Loss: 0.289, Val Loss: 0.407, Train DICE: 0.967, Val DICE: 0.949\n",
            "Best validation dice coefficient improved to 0.949\n",
            "Epoch: 7/50 |  Train Loss: 0.274, Val Loss: 0.393, Train DICE: 0.970, Val DICE: 0.949\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 8/50 |  Train Loss: 0.260, Val Loss: 0.386, Train DICE: 0.973, Val DICE: 0.946\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 9/50 |  Train Loss: 0.248, Val Loss: 0.369, Train DICE: 0.976, Val DICE: 0.949\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 10/50 |  Train Loss: 0.239, Val Loss: 0.364, Train DICE: 0.976, Val DICE: 0.946\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.230, Val Loss: 0.351, Train DICE: 0.979, Val DICE: 0.954\n",
            "Best validation dice coefficient improved to 0.954\n",
            "Epoch: 12/50 |  Train Loss: 0.227, Val Loss: 0.349, Train DICE: 0.981, Val DICE: 0.954\n",
            "Best validation dice coefficient improved to 0.954\n",
            "Epoch: 13/50 |  Train Loss: 0.225, Val Loss: 0.350, Train DICE: 0.982, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.224, Val Loss: 0.347, Train DICE: 0.982, Val DICE: 0.954\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 15/50 |  Train Loss: 0.222, Val Loss: 0.345, Train DICE: 0.983, Val DICE: 0.954\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 16/50 |  Train Loss: 0.221, Val Loss: 0.346, Train DICE: 0.983, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 17/50 |  Train Loss: 0.220, Val Loss: 0.345, Train DICE: 0.983, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 17 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.532, Val Loss: 0.694, Train DICE: 0.709, Val DICE: 0.850\n",
            "Best validation dice coefficient improved to 0.850\n",
            "Epoch: 2/50 |  Train Loss: 0.365, Val Loss: 0.457, Train DICE: 0.929, Val DICE: 0.927\n",
            "Best validation dice coefficient improved to 0.927\n",
            "Epoch: 3/50 |  Train Loss: 0.310, Val Loss: 0.418, Train DICE: 0.949, Val DICE: 0.943\n",
            "Best validation dice coefficient improved to 0.943\n",
            "Epoch: 4/50 |  Train Loss: 0.285, Val Loss: 0.396, Train DICE: 0.958, Val DICE: 0.944\n",
            "Best validation dice coefficient improved to 0.944\n",
            "Epoch: 5/50 |  Train Loss: 0.266, Val Loss: 0.376, Train DICE: 0.964, Val DICE: 0.945\n",
            "Best validation dice coefficient improved to 0.945\n",
            "Epoch: 6/50 |  Train Loss: 0.250, Val Loss: 0.363, Train DICE: 0.968, Val DICE: 0.942\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 7/50 |  Train Loss: 0.236, Val Loss: 0.342, Train DICE: 0.972, Val DICE: 0.950\n",
            "Best validation dice coefficient improved to 0.950\n",
            "Epoch: 8/50 |  Train Loss: 0.225, Val Loss: 0.320, Train DICE: 0.973, Val DICE: 0.955\n",
            "Best validation dice coefficient improved to 0.955\n",
            "Epoch: 9/50 |  Train Loss: 0.214, Val Loss: 0.313, Train DICE: 0.975, Val DICE: 0.951\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 10/50 |  Train Loss: 0.204, Val Loss: 0.306, Train DICE: 0.976, Val DICE: 0.950\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.194, Val Loss: 0.287, Train DICE: 0.977, Val DICE: 0.957\n",
            "Best validation dice coefficient improved to 0.957\n",
            "Epoch: 12/50 |  Train Loss: 0.185, Val Loss: 0.280, Train DICE: 0.978, Val DICE: 0.956\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 13/50 |  Train Loss: 0.176, Val Loss: 0.274, Train DICE: 0.980, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.169, Val Loss: 0.265, Train DICE: 0.981, Val DICE: 0.954\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 15/50 |  Train Loss: 0.162, Val Loss: 0.256, Train DICE: 0.981, Val DICE: 0.955\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 16/50 |  Train Loss: 0.155, Val Loss: 0.250, Train DICE: 0.983, Val DICE: 0.958\n",
            "Best validation dice coefficient improved to 0.958\n",
            "Epoch: 17/50 |  Train Loss: 0.153, Val Loss: 0.251, Train DICE: 0.985, Val DICE: 0.957\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 18/50 |  Train Loss: 0.152, Val Loss: 0.250, Train DICE: 0.985, Val DICE: 0.957\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 19/50 |  Train Loss: 0.150, Val Loss: 0.248, Train DICE: 0.986, Val DICE: 0.958\n",
            "Best validation dice coefficient improved to 0.958\n",
            "Epoch: 20/50 |  Train Loss: 0.150, Val Loss: 0.247, Train DICE: 0.985, Val DICE: 0.958\n",
            "Best validation dice coefficient improved to 0.958\n",
            "Epoch: 21/50 |  Train Loss: 0.149, Val Loss: 0.247, Train DICE: 0.986, Val DICE: 0.957\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 22/50 |  Train Loss: 0.148, Val Loss: 0.245, Train DICE: 0.986, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 23/50 |  Train Loss: 0.147, Val Loss: 0.245, Train DICE: 0.986, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 24/50 |  Train Loss: 0.146, Val Loss: 0.242, Train DICE: 0.986, Val DICE: 0.959\n",
            "Best validation dice coefficient improved to 0.959\n",
            "Epoch: 25/50 |  Train Loss: 0.145, Val Loss: 0.244, Train DICE: 0.987, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 26/50 |  Train Loss: 0.144, Val Loss: 0.248, Train DICE: 0.987, Val DICE: 0.955\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 27/50 |  Train Loss: 0.144, Val Loss: 0.240, Train DICE: 0.987, Val DICE: 0.959\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 28/50 |  Train Loss: 0.142, Val Loss: 0.242, Train DICE: 0.987, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 29/50 |  Train Loss: 0.142, Val Loss: 0.241, Train DICE: 0.987, Val DICE: 0.958\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 29 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.479, Val Loss: 0.598, Train DICE: 0.732, Val DICE: 0.868\n",
            "Best validation dice coefficient improved to 0.868\n",
            "Epoch: 2/50 |  Train Loss: 0.335, Val Loss: 0.406, Train DICE: 0.916, Val DICE: 0.928\n",
            "Best validation dice coefficient improved to 0.928\n",
            "Epoch: 3/50 |  Train Loss: 0.283, Val Loss: 0.384, Train DICE: 0.946, Val DICE: 0.938\n",
            "Best validation dice coefficient improved to 0.938\n",
            "Epoch: 4/50 |  Train Loss: 0.258, Val Loss: 0.369, Train DICE: 0.954, Val DICE: 0.928\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 5/50 |  Train Loss: 0.238, Val Loss: 0.335, Train DICE: 0.963, Val DICE: 0.942\n",
            "Best validation dice coefficient improved to 0.942\n",
            "Epoch: 6/50 |  Train Loss: 0.223, Val Loss: 0.312, Train DICE: 0.967, Val DICE: 0.949\n",
            "Best validation dice coefficient improved to 0.949\n",
            "Epoch: 7/50 |  Train Loss: 0.209, Val Loss: 0.306, Train DICE: 0.970, Val DICE: 0.945\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 8/50 |  Train Loss: 0.198, Val Loss: 0.287, Train DICE: 0.972, Val DICE: 0.949\n",
            "Best validation dice coefficient improved to 0.949\n",
            "Epoch: 9/50 |  Train Loss: 0.186, Val Loss: 0.271, Train DICE: 0.975, Val DICE: 0.952\n",
            "Best validation dice coefficient improved to 0.952\n",
            "Epoch: 10/50 |  Train Loss: 0.177, Val Loss: 0.263, Train DICE: 0.976, Val DICE: 0.951\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.169, Val Loss: 0.260, Train DICE: 0.976, Val DICE: 0.947\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 12/50 |  Train Loss: 0.160, Val Loss: 0.249, Train DICE: 0.978, Val DICE: 0.949\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 13/50 |  Train Loss: 0.151, Val Loss: 0.237, Train DICE: 0.980, Val DICE: 0.952\n",
            "Best validation dice coefficient improved to 0.952\n",
            "Epoch: 14/50 |  Train Loss: 0.144, Val Loss: 0.224, Train DICE: 0.980, Val DICE: 0.954\n",
            "Best validation dice coefficient improved to 0.954\n",
            "Epoch: 15/50 |  Train Loss: 0.137, Val Loss: 0.215, Train DICE: 0.981, Val DICE: 0.956\n",
            "Best validation dice coefficient improved to 0.956\n",
            "Epoch: 16/50 |  Train Loss: 0.130, Val Loss: 0.234, Train DICE: 0.982, Val DICE: 0.940\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 17/50 |  Train Loss: 0.125, Val Loss: 0.207, Train DICE: 0.982, Val DICE: 0.954\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 18/50 |  Train Loss: 0.119, Val Loss: 0.197, Train DICE: 0.983, Val DICE: 0.956\n",
            "Best validation dice coefficient improved to 0.956\n",
            "Epoch: 19/50 |  Train Loss: 0.114, Val Loss: 0.188, Train DICE: 0.983, Val DICE: 0.958\n",
            "Best validation dice coefficient improved to 0.958\n",
            "Epoch: 20/50 |  Train Loss: 0.109, Val Loss: 0.191, Train DICE: 0.983, Val DICE: 0.954\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 21/50 |  Train Loss: 0.105, Val Loss: 0.183, Train DICE: 0.984, Val DICE: 0.957\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 22/50 |  Train Loss: 0.102, Val Loss: 0.181, Train DICE: 0.983, Val DICE: 0.954\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 23/50 |  Train Loss: 0.098, Val Loss: 0.179, Train DICE: 0.984, Val DICE: 0.953\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 24/50 |  Train Loss: 0.093, Val Loss: 0.175, Train DICE: 0.986, Val DICE: 0.955\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 24 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.425, Val Loss: 0.551, Train DICE: 0.751, Val DICE: 0.824\n",
            "Best validation dice coefficient improved to 0.824\n",
            "Epoch: 2/50 |  Train Loss: 0.297, Val Loss: 0.366, Train DICE: 0.899, Val DICE: 0.905\n",
            "Best validation dice coefficient improved to 0.905\n",
            "Epoch: 3/50 |  Train Loss: 0.252, Val Loss: 0.333, Train DICE: 0.939, Val DICE: 0.929\n",
            "Best validation dice coefficient improved to 0.929\n",
            "Epoch: 4/50 |  Train Loss: 0.228, Val Loss: 0.313, Train DICE: 0.952, Val DICE: 0.937\n",
            "Best validation dice coefficient improved to 0.937\n",
            "Epoch: 5/50 |  Train Loss: 0.209, Val Loss: 0.289, Train DICE: 0.961, Val DICE: 0.947\n",
            "Best validation dice coefficient improved to 0.947\n",
            "Epoch: 6/50 |  Train Loss: 0.194, Val Loss: 0.278, Train DICE: 0.967, Val DICE: 0.947\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 7/50 |  Train Loss: 0.182, Val Loss: 0.277, Train DICE: 0.969, Val DICE: 0.932\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 8/50 |  Train Loss: 0.170, Val Loss: 0.246, Train DICE: 0.972, Val DICE: 0.951\n",
            "Best validation dice coefficient improved to 0.951\n",
            "Epoch: 9/50 |  Train Loss: 0.160, Val Loss: 0.235, Train DICE: 0.975, Val DICE: 0.951\n",
            "Best validation dice coefficient improved to 0.951\n",
            "Epoch: 10/50 |  Train Loss: 0.151, Val Loss: 0.226, Train DICE: 0.976, Val DICE: 0.949\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 0.142, Val Loss: 0.217, Train DICE: 0.977, Val DICE: 0.952\n",
            "Best validation dice coefficient improved to 0.952\n",
            "Epoch: 12/50 |  Train Loss: 0.134, Val Loss: 0.210, Train DICE: 0.978, Val DICE: 0.949\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 13/50 |  Train Loss: 0.127, Val Loss: 0.205, Train DICE: 0.978, Val DICE: 0.946\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.119, Val Loss: 0.192, Train DICE: 0.980, Val DICE: 0.950\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 15/50 |  Train Loss: 0.113, Val Loss: 0.179, Train DICE: 0.981, Val DICE: 0.954\n",
            "Best validation dice coefficient improved to 0.954\n",
            "Epoch: 16/50 |  Train Loss: 0.107, Val Loss: 0.179, Train DICE: 0.981, Val DICE: 0.951\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 17/50 |  Train Loss: 0.100, Val Loss: 0.164, Train DICE: 0.983, Val DICE: 0.957\n",
            "Best validation dice coefficient improved to 0.957\n",
            "Epoch: 18/50 |  Train Loss: 0.096, Val Loss: 0.167, Train DICE: 0.983, Val DICE: 0.952\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 19/50 |  Train Loss: 0.092, Val Loss: 0.167, Train DICE: 0.983, Val DICE: 0.950\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 20/50 |  Train Loss: 0.088, Val Loss: 0.159, Train DICE: 0.983, Val DICE: 0.952\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 21/50 |  Train Loss: 0.083, Val Loss: 0.154, Train DICE: 0.984, Val DICE: 0.950\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 22/50 |  Train Loss: 0.079, Val Loss: 0.148, Train DICE: 0.987, Val DICE: 0.956\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 22 epochs\n"
          ]
        }
      ],
      "source": [
        "num_epochs=50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(n_channels=1, n_classes=2, bilinear=False).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
        "train_loss_history, train_dice_history, val_loss_history, val_dice_history, e= train_model_early_stopping(train_dataloader, val_dataloader, tversky_loss, optimizer, scheduler, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhtJjM0DcAIb",
        "outputId": "cc49d3e4-c218-4862-cecb-416cc505c225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/50 |  Train Loss: 0.325, Val Loss: 0.385, Train DICE: 0.688, Val DICE: 0.711\n",
            "Best validation dice coefficient improved to 0.711\n",
            "Epoch: 2/50 |  Train Loss: 0.298, Val Loss: 0.385, Train DICE: 0.702, Val DICE: 0.711\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 3/50 |  Train Loss: 0.298, Val Loss: 0.385, Train DICE: 0.702, Val DICE: 0.711\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 4/50 |  Train Loss: 0.299, Val Loss: 0.388, Train DICE: 0.701, Val DICE: 0.709\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 5/50 |  Train Loss: 0.300, Val Loss: 0.388, Train DICE: 0.700, Val DICE: 0.709\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 6/50 |  Train Loss: 0.300, Val Loss: 0.388, Train DICE: 0.700, Val DICE: 0.709\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 6 epochs\n",
            "Epoch: 1/50 |  Train Loss: 1.627, Val Loss: 1.581, Train DICE: 0.495, Val DICE: 0.500\n",
            "Best validation dice coefficient improved to 0.500\n",
            "Epoch: 2/50 |  Train Loss: 1.169, Val Loss: 1.531, Train DICE: 0.616, Val DICE: 0.678\n",
            "Best validation dice coefficient improved to 0.678\n",
            "Epoch: 3/50 |  Train Loss: 0.988, Val Loss: 1.322, Train DICE: 0.679, Val DICE: 0.693\n",
            "Best validation dice coefficient improved to 0.693\n",
            "Epoch: 4/50 |  Train Loss: 0.911, Val Loss: 1.286, Train DICE: 0.701, Val DICE: 0.721\n",
            "Best validation dice coefficient improved to 0.721\n",
            "Epoch: 5/50 |  Train Loss: 0.876, Val Loss: 1.193, Train DICE: 0.724, Val DICE: 0.736\n",
            "Best validation dice coefficient improved to 0.736\n",
            "Epoch: 6/50 |  Train Loss: 0.796, Val Loss: 1.122, Train DICE: 0.749, Val DICE: 0.741\n",
            "Best validation dice coefficient improved to 0.741\n",
            "Epoch: 7/50 |  Train Loss: 0.741, Val Loss: 1.021, Train DICE: 0.772, Val DICE: 0.813\n",
            "Best validation dice coefficient improved to 0.813\n",
            "Epoch: 8/50 |  Train Loss: 0.629, Val Loss: 0.809, Train DICE: 0.832, Val DICE: 0.878\n",
            "Best validation dice coefficient improved to 0.878\n",
            "Epoch: 9/50 |  Train Loss: 0.503, Val Loss: 0.646, Train DICE: 0.878, Val DICE: 0.885\n",
            "Best validation dice coefficient improved to 0.885\n",
            "Epoch: 10/50 |  Train Loss: 0.409, Val Loss: 0.551, Train DICE: 0.906, Val DICE: 0.906\n",
            "Best validation dice coefficient improved to 0.906\n",
            "Epoch: 11/50 |  Train Loss: 0.343, Val Loss: 0.593, Train DICE: 0.920, Val DICE: 0.895\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 12/50 |  Train Loss: 0.327, Val Loss: 0.457, Train DICE: 0.925, Val DICE: 0.920\n",
            "Best validation dice coefficient improved to 0.920\n",
            "Epoch: 13/50 |  Train Loss: 0.308, Val Loss: 0.486, Train DICE: 0.929, Val DICE: 0.919\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 14/50 |  Train Loss: 0.307, Val Loss: 0.546, Train DICE: 0.929, Val DICE: 0.902\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 15/50 |  Train Loss: 0.287, Val Loss: 0.463, Train DICE: 0.933, Val DICE: 0.914\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 16/50 |  Train Loss: 0.281, Val Loss: 0.472, Train DICE: 0.935, Val DICE: 0.918\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 17/50 |  Train Loss: 0.263, Val Loss: 0.474, Train DICE: 0.939, Val DICE: 0.919\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 17 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1/50 |  Train Loss: 0.406, Val Loss: 0.532, Train DICE: 0.689, Val DICE: 0.711\n",
            "Best validation dice coefficient improved to 0.711\n",
            "Epoch: 2/50 |  Train Loss: 0.401, Val Loss: 0.532, Train DICE: 0.702, Val DICE: 0.711\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 3/50 |  Train Loss: 0.401, Val Loss: 0.532, Train DICE: 0.702, Val DICE: 0.711\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 4/50 |  Train Loss: 0.401, Val Loss: 0.532, Train DICE: 0.703, Val DICE: 0.711\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 5/50 |  Train Loss: 0.401, Val Loss: 0.532, Train DICE: 0.702, Val DICE: 0.711\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 6/50 |  Train Loss: 0.401, Val Loss: 0.532, Train DICE: 0.702, Val DICE: 0.711\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 6 epochs\n",
            "Epoch: 1/50 |  Train Loss: 0.556, Val Loss: 0.750, Train DICE: 0.502, Val DICE: 0.519\n",
            "Best validation dice coefficient improved to 0.519\n",
            "Epoch: 2/50 |  Train Loss: 0.533, Val Loss: 0.730, Train DICE: 0.507, Val DICE: 0.519\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 3/50 |  Train Loss: 0.527, Val Loss: 0.716, Train DICE: 0.557, Val DICE: 0.622\n",
            "Best validation dice coefficient improved to 0.622\n",
            "Epoch: 4/50 |  Train Loss: 0.508, Val Loss: 0.676, Train DICE: 0.664, Val DICE: 0.748\n",
            "Best validation dice coefficient improved to 0.748\n",
            "Epoch: 5/50 |  Train Loss: 0.490, Val Loss: 0.656, Train DICE: 0.724, Val DICE: 0.776\n",
            "Best validation dice coefficient improved to 0.776\n",
            "Epoch: 6/50 |  Train Loss: 0.486, Val Loss: 0.642, Train DICE: 0.748, Val DICE: 0.773\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 7/50 |  Train Loss: 0.483, Val Loss: 0.641, Train DICE: 0.764, Val DICE: 0.767\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 8/50 |  Train Loss: 0.483, Val Loss: 0.641, Train DICE: 0.761, Val DICE: 0.766\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 9/50 |  Train Loss: 0.485, Val Loss: 0.644, Train DICE: 0.759, Val DICE: 0.762\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 10/50 |  Train Loss: 0.483, Val Loss: 0.639, Train DICE: 0.762, Val DICE: 0.774\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 10 epochs\n",
            "Epoch: 1/50 |  Train Loss: 1.964, Val Loss: 2.600, Train DICE: 0.644, Val DICE: 0.675\n",
            "Best validation dice coefficient improved to 0.675\n",
            "Epoch: 2/50 |  Train Loss: 1.951, Val Loss: 2.604, Train DICE: 0.675, Val DICE: 0.673\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 3/50 |  Train Loss: 1.946, Val Loss: 2.577, Train DICE: 0.714, Val DICE: 0.736\n",
            "Best validation dice coefficient improved to 0.736\n",
            "Epoch: 4/50 |  Train Loss: 1.918, Val Loss: 2.564, Train DICE: 0.752, Val DICE: 0.743\n",
            "Best validation dice coefficient improved to 0.743\n",
            "Epoch: 5/50 |  Train Loss: 1.916, Val Loss: 2.564, Train DICE: 0.757, Val DICE: 0.743\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 6/50 |  Train Loss: 1.915, Val Loss: 2.564, Train DICE: 0.757, Val DICE: 0.742\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 7/50 |  Train Loss: 1.915, Val Loss: 2.563, Train DICE: 0.757, Val DICE: 0.744\n",
            "Best validation dice coefficient improved to 0.744\n",
            "Epoch: 8/50 |  Train Loss: 1.918, Val Loss: 2.565, Train DICE: 0.753, Val DICE: 0.741\n",
            "No improvement in validation dice coefficient for 1 consecutive epochs\n",
            "Epoch: 9/50 |  Train Loss: 1.917, Val Loss: 2.566, Train DICE: 0.753, Val DICE: 0.740\n",
            "No improvement in validation dice coefficient for 2 consecutive epochs\n",
            "Epoch: 10/50 |  Train Loss: 1.920, Val Loss: 2.567, Train DICE: 0.748, Val DICE: 0.739\n",
            "No improvement in validation dice coefficient for 3 consecutive epochs\n",
            "Epoch: 11/50 |  Train Loss: 1.920, Val Loss: 2.566, Train DICE: 0.749, Val DICE: 0.740\n",
            "No improvement in validation dice coefficient for 4 consecutive epochs\n",
            "Epoch: 12/50 |  Train Loss: 1.919, Val Loss: 2.566, Train DICE: 0.750, Val DICE: 0.739\n",
            "No improvement in validation dice coefficient for 5 consecutive epochs\n",
            "Early stopping triggered after 12 epochs\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_epochs=50\n",
        "dict_lf_to_parameters={}\n",
        "lf_train_loss_history={}\n",
        "lf_train_dice_history={}\n",
        "lf_val_loss_history={}\n",
        "lf_val_dice_history={}\n",
        "dict_pred_dice={}\n",
        "dict_stopping_epoch={}\n",
        "dict_time_taken={}\n",
        "\n",
        "# loss functions to compare\n",
        "loss_funcs = [dice_coef_loss,bce_dice_loss,TverskyLoss(),FocalLoss(),lovasz_softmax_flat]\n",
        "for lf in loss_funcs:\n",
        "  start_time = time.time()\n",
        "  model = FCN_flexible(input_shape=(1, 128, 128), num_classes=2, dropout_prob=0.5, num_layers=5).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
        "  train_loss_history, train_dice_history, val_loss_history, val_dice_history, e= train_model_early_stopping(train_dataloader, val_dataloader, lf, optimizer, scheduler, num_epochs)\n",
        "  dict_pred_dice[lf]=prediction_dice(model, test_dataloader)\n",
        "  end_time = time.time()\n",
        "  lf_train_loss_history[lf]=train_loss_history\n",
        "  lf_train_dice_history[lf]=train_dice_history\n",
        "  lf_val_loss_history[lf]=val_loss_history\n",
        "  lf_val_dice_history[lf]=val_dice_history\n",
        "  dict_stopping_epoch[lf]=e\n",
        "  dict_time_taken[lf]=end_time - start_time\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lVoPfrX6aPx"
      },
      "outputs": [],
      "source": [
        "for lf in loss_funcs:\n",
        "\n",
        "  plot_dice_history('DICE FCN with {}'.format(lf), lf_train_dice_history[lf], lf_val_dice_history[lf], len(lf_val_dice_history[lf]))\n",
        "  plot_loss_history('LOSS FCN with {}'.format(lf), lf_train_loss_history[lf], lf_val_loss_history[lf],len(lf_val_loss_history[lf]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qAFwsFOpUq1"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# Define the range of values to search over\n",
        "alphas = [0.3, 0.5, 0.7]\n",
        "betas = [0.3, 0.5, 0.7]\n",
        "smooths = [1.0, 1.5, 2.0]\n",
        "\n",
        "# Perform the grid search experiment\n",
        "results = []\n",
        "for alpha, beta, smooth in itertools.product(alphas, betas, smooths):\n",
        "    print(f'Training TverskyLoss with alpha={alpha}, beta={beta}, smooth={smooth}...')\n",
        "    loss_func = TverskyLoss(alpha=0.7, beta=0.7, smooth=smooth)\n",
        "    model = FCN_flexible(input_shape=(1, 128, 128), num_classes=2, dropout_prob=0.5, num_layers=4).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, factor=0.5, verbose=True)\n",
        "    train_loss_history, train_dice_history, val_loss_history, val_dice_history, epochs = train_model_early_stopping(train_dataloader, val_dataloader, loss_func, optimizer, scheduler, num_epochs=50)\n",
        "\n",
        "    train_loss_history, train_dice_history, val_loss_history, val_dice_history, epochs = train_model_early_stopping(train_dataloader, val_dataloader, loss_func, optimizer, scheduler, num_epochs=50)\n",
        "    results.append((alpha, beta, smooth, epochs, max(val_dice_history)))\n",
        "\n",
        "# Print the results of the grid search\n",
        "print('\\nGrid Search Results:')\n",
        "for alpha, beta, smooth, epochs, val_dice in results:\n",
        "    print(f'alpha={alpha}, beta={beta}, smooth={smooth}, epochs={epochs}, val_dice={val_dice:.3f}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
