{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p_sWZmn7iC5I"
      },
      "source": [
        "Load data, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# load \n",
        "X_Guys = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/X_Guys.npy')\n",
        "y_Guys = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/y_Guys.npy')\n",
        "ids_Guys = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/ids_Guys.npy')\n",
        "X_HH = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/X_HH.npy')\n",
        "y_HH = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/y_HH.npy')\n",
        "ids_HH = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/ids_HH.npy')\n",
        "X_IOP = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/X_IOP.npy')\n",
        "y_IOP = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/y_IOP.npy')\n",
        "ids_IOP = np.load('/content/drive/MyDrive/dhl_exam/data/subcortical/ids_IOP.npy')\n",
        "\n",
        "#center data\n",
        "def centring(X):\n",
        "    X=np.asarray(X)\n",
        "    epsilon = 1e-7 \n",
        "    mean = np.mean(X, axis=0, keepdims=True)\n",
        "    std = np.std(X, axis=0, keepdims=True)\n",
        "    centered_array = (X - mean) / (std+epsilon)\n",
        "    return centered_array\n",
        "\n",
        "\n",
        "def to_one_hot_5_matrix_batch(batch_matrix):\n",
        "    \n",
        "    batch_matrix = np.array(batch_matrix, dtype='int')\n",
        "    one_hot = np.zeros((batch_matrix.shape[0], 5, batch_matrix.shape[1], batch_matrix.shape[2]), dtype=float)\n",
        "    one_hot[:, 0] = batch_matrix == 0\n",
        "    one_hot[:, 1] = batch_matrix == 1\n",
        "    one_hot[:, 2] = batch_matrix == 2\n",
        "    one_hot[:, 3] = batch_matrix == 3\n",
        "    one_hot[:, 4] = batch_matrix == 4\n",
        "    return one_hot\n",
        "\n",
        "\n",
        "X_Guys_centered=centring(X_Guys)\n",
        "X_HH_centered=centring(X_HH)\n",
        "X_IOP_centered=centring(X_IOP)\n",
        "# producing required train / val / test split\n",
        "print(\"initial shapes\")\n",
        "print(X_Guys.shape)\n",
        "print(y_Guys.shape)\n",
        "print(ids_Guys.shape)\n",
        "print(X_HH.shape)\n",
        "print(y_HH.shape)\n",
        "print(ids_HH.shape)\n",
        "print(X_IOP.shape)\n",
        "print(y_IOP.shape)\n",
        "print(ids_IOP.shape)\n",
        "\n",
        "combined_Guys_HH_X = np.concatenate([X_Guys_centered, X_HH_centered], axis=0)\n",
        "combined_Guys_HH_y = np.concatenate([y_Guys, y_HH], axis=0)\n",
        "\n",
        "X_train = torch.Tensor(combined_Guys_HH_X[0:int(len(combined_Guys_HH_X)*0.85)])\n",
        "y_train = torch.Tensor(combined_Guys_HH_y[0:int(len(combined_Guys_HH_y)*0.85)])\n",
        "\n",
        "# val data 15%\n",
        "X_val = torch.Tensor(combined_Guys_HH_X[int(len(combined_Guys_HH_X)*0.85):int(len(combined_Guys_HH_X))])\n",
        "y_val = torch.Tensor(combined_Guys_HH_y[int(len(combined_Guys_HH_y)*0.85):int(len(combined_Guys_HH_y))])\n",
        "#test data from IOP data\n",
        "X_test =  torch.Tensor(X_IOP_centered[0:int(len(X_IOP_centered))])\n",
        "y_test = torch.Tensor(y_IOP[0:int(len(y_IOP))])\n",
        "\n",
        "print(\"Check after split\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "# slice data into 2D\n",
        "def reslice(x, split_size):\n",
        "  temp = torch.split(x,split_size,dim=1)\n",
        "  output=[]\n",
        "  for i in range(len(temp)):\n",
        "    output.append(temp[i])\n",
        "  output=torch.cat(output, dim=0)\n",
        "  return output\n",
        "\n",
        "\n",
        "\n",
        "X_train=X_train[:,10,:,:]\n",
        "X_val=X_val[:,10,:,:]\n",
        "X_test=X_test[:,10,:,:]\n",
        "y_train=y_train[:,10,:,:]\n",
        "y_val=y_val[:,10,:,:]\n",
        "y_test=y_test[:,10,:,:]\n",
        "\n",
        "\n",
        "#introduce channel\n",
        "X_train=torch.reshape(X_train,(len(X_train),1,128,128))\n",
        "X_val=torch.reshape(X_val,(len(X_val),1,128,128))\n",
        "X_test=torch.reshape(X_test,(len(X_test),1,128,128))\n",
        "y_train = torch.reshape(y_train,(len(y_train),128,128))\n",
        "y_val= torch.reshape(y_val,(len(y_val),128,128))\n",
        "y_test = torch.reshape(y_test,(len(y_test),128,128))\n",
        "y_train = to_one_hot_5_matrix_batch(y_train)\n",
        "y_val= to_one_hot_5_matrix_batch(y_val)\n",
        "y_test =to_one_hot_5_matrix_batch((y_test))\n",
        "\n",
        "\n",
        "print(\"Check shapes after slicing into 2D\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "\n",
        "X_train=np.asarray(X_train)\n",
        "X_val=np.asarray(X_val)\n",
        "X_test=np.asarray(X_test)\n",
        "y_train=np.asarray(y_train)\n",
        "y_val=np.asarray(y_val)\n",
        "y_test=np.asarray(y_test)\n",
        "\n",
        "\n",
        "class numpy_dataset(Dataset): \n",
        "    def __init__(self, data, target): \n",
        "        self.data =  torch.from_numpy(data)\n",
        "        self.target = torch.from_numpy(target)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "train_dataset = numpy_dataset(X_train, y_train)\n",
        "val_dataset = numpy_dataset(X_val, y_val)\n",
        "test_dataset = numpy_dataset(X_test, y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(SegNet, self).__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(512)\n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(512)\n",
        "        self.conv7 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "        self.bn7 = nn.BatchNorm2d(256)\n",
        "        self.conv8 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
        "        self.bn8 = nn.BatchNorm2d(128)\n",
        "        self.conv9 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
        "        self.bn9 = nn.BatchNorm2d(64)\n",
        "        self.conv10 = nn.Conv2d(64, num_classes, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.unpool = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x, pool1_indices = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x, pool2_indices = self.pool(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x, pool3_indices = self.pool(x)\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x, pool4_indices = self.pool(x)\n",
        "        x = F.relu(self.bn5(self.conv5(x)))\n",
        "        x, pool5_indices = self.pool(x)\n",
        "        x = self.unpool(x, pool5_indices)\n",
        "        x = F.relu(self.bn6(self.conv6(x)))\n",
        "        x = self.unpool(x, pool4_indices)\n",
        "        x = F.relu(self.bn7(self.conv7(x)))\n",
        "        x = self.unpool(x, pool3_indices)\n",
        "        x = F.relu(self.bn8(self.conv8(x)))\n",
        "        x = self.unpool(x, pool2_indices)\n",
        "        x = F.relu(self.bn9(self.conv9(x)))\n",
        "        x = self.conv10(x)\n",
        "        x = F.interpolate(x, size=(128, 128), mode='bilinear', align_corners=False)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "\n",
        "class FCN_flexible(nn.Module):\n",
        "    def __init__(self, input_shape=(1, 128, 128), num_classes=2, dropout_prob=0.5, num_layers=5):\n",
        "        super(FCN_flexible, self).__init__()\n",
        "        encoder_layers = []\n",
        "        in_channels = input_shape[0]\n",
        "        for i in range(num_layers):\n",
        "            out_channels = 64 * (2 ** i)\n",
        "            encoder_layers.extend([\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout_prob),\n",
        "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "\n",
        "        self.encoder = nn.Sequential(*encoder_layers)\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels * 2, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_prob),\n",
        "            nn.Conv2d(in_channels * 2, in_channels, kernel_size=1)\n",
        "        )\n",
        "        decoder_layers = []\n",
        "        for i in range(num_layers - 1, -1, -1):\n",
        "            out_channels = 64 * (2 ** i)\n",
        "            decoder_layers.extend([\n",
        "                nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(dropout_prob)\n",
        "            ])\n",
        "            in_channels = out_channels\n",
        "\n",
        "        decoder_layers.extend([\n",
        "            nn.Conv2d(out_channels, num_classes, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        ])\n",
        "\n",
        "        self.decoder = nn.Sequential(*decoder_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.middle(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv = conv_block(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(self.pool(x))\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "        self.conv = conv_block(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat((skip, x), dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "        self.init_conv = conv_block(in_channels, 64)\n",
        "        self.encoders = nn.ModuleList([\n",
        "            Encoder(64, 128),\n",
        "            Encoder(128, 256),\n",
        "            Encoder(256, 512),\n",
        "            Encoder(512, 1024)\n",
        "        ])\n",
        "        self.decoders = nn.ModuleList([\n",
        "            Decoder(1024, 512),\n",
        "            Decoder(512, 256),\n",
        "            Decoder(256, 128),\n",
        "            Decoder(128, 64)\n",
        "        ])\n",
        "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.init_conv(x)\n",
        "        skips = [x1]\n",
        "        for encoder in self.encoders:\n",
        "            skips.append(encoder(skips[-1]))\n",
        "\n",
        "        x = skips.pop()\n",
        "        for decoder in self.decoders:\n",
        "            x = decoder(x, skips.pop())\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVtoLB4yiXjV",
        "outputId": "7004909e-dd0d-485d-8eb0-f85c6cbd587c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FCN_flexible(\n",
              "  (encoder): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Dropout(p=0.5, inplace=False)\n",
              "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Dropout(p=0.5, inplace=False)\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (middle): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (decoder): Sequential(\n",
              "    (0): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Dropout(p=0.5, inplace=False)\n",
              "    (9): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Dropout(p=0.5, inplace=False)\n",
              "    (12): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (13): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#unet\n",
        "unet = UNet(n_channels=1, n_classes=5).to(device)\n",
        "unet.load_state_dict(torch.load(\"/content/drive/MyDrive/dhl_exam/models/unet_model_subcortical.pth\"))\n",
        "unet.eval()\n",
        "\n",
        "#segnet\n",
        "segnet = SegNet(in_channels=1, num_classes=5).to(device)\n",
        "segnet.load_state_dict(torch.load(\"/content/drive/MyDrive/dhl_exam/models/segnet_model_subcortical.pth\"))\n",
        "segnet.eval()\n",
        "\n",
        "#FCN 7\n",
        "fcn7= FCN_flexible(input_shape=(1, 128, 128), num_classes=5, dropout_prob=0.5, num_layers=7).to(device)\n",
        "fcn7.load_state_dict(torch.load(\"/content/drive/MyDrive/dhl_exam/models/fcn7_model_subcortical.pth\"))\n",
        "fcn7.eval()\n",
        "\n",
        "#FCN 6\n",
        "fcn6= FCN_flexible(input_shape=(1, 128, 128), num_classes=5, dropout_prob=0.5, num_layers=6).to(device)\n",
        "fcn6.load_state_dict(torch.load(\"/content/drive/MyDrive/dhl_exam/models/fcn6_model_subcortical.pth\"))\n",
        "fcn6.eval()\n",
        "\n",
        "#FCN 5\n",
        "fcn5= FCN_flexible(input_shape=(1, 128, 128), num_classes=5, dropout_prob=0.5, num_layers=5).to(device)\n",
        "fcn5.load_state_dict(torch.load(\"/content/drive/MyDrive/dhl_exam/models/fcn5_model_subcortical.pth\"))\n",
        "fcn5.eval()\n",
        "\n",
        "#FCN 4\n",
        "fcn4= FCN_flexible(input_shape=(1, 128, 128), num_classes=5, dropout_prob=0.5, num_layers=4).to(device)\n",
        "fcn4.load_state_dict(torch.load(\"/content/drive/MyDrive/dhl_exam/models/fcn4_model_subcortical.pth\"))\n",
        "fcn4.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6ZvKdLNjvVC"
      },
      "source": [
        "Visualise data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G--jkECOo2J7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def sum_pixels_per_class(one_hot_tensor):\n",
        "    one_hot_tensor=torch.from_numpy(one_hot_tensor)\n",
        "    assert one_hot_tensor.shape == (4, 128, 128), \"The input tensor shape should be (2, 128, 128)\"\n",
        "    pixel_sums = torch.sum(one_hot_tensor, dim=(1, 2))\n",
        "    \n",
        "    print(f\"Sum of pixels for Class 0: {pixel_sums[0]}\")\n",
        "    print(f\"Sum of pixels for Class 1: {pixel_sums[1]}\")\n",
        "    print(f\"Sum of pixels for Class 0: {pixel_sums[2]}\")\n",
        "    print(f\"Sum of pixels for Class 1: {pixel_sums[3]}\")\n",
        "    return pixel_sums\n",
        "\n",
        "def sum_pixels_per_class_batch(one_hot_batch_tensor):\n",
        "    assert one_hot_batch_tensor.shape == (40, 4, 128, 128), \"The input tensor shape should be (40, 2, 128, 128)\"\n",
        "    pixel_sums = torch.sum(one_hot_batch_tensor, dim=(0, 2, 3))\n",
        "    return pixel_sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngb6ZYMTtMaF",
        "outputId": "dbf33dcd-029b-44c4-805a-b5fd40f1189d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2840, 1, 128, 128)\n",
            "(2840, 4, 128, 128)\n"
          ]
        }
      ],
      "source": [
        "# data loader to load all testing data in sequence \n",
        "X_test =  torch.Tensor(X_IOP_centered[0:int(len(X_IOP_centered))])\n",
        "y_test = torch.Tensor(y_IOP[0:int(len(y_IOP))])\n",
        "X_test_slices = np.asarray(reslice(X_test,1))\n",
        "y_test_slices = reslice(y_test,1).reshape((2840, 128, 128))\n",
        "y_test_slices = to_one_hot_5_matrix_batch(y_test_slices)\n",
        "print(X_test_slices.shape)\n",
        "print(y_test_slices.shape)\n",
        "\n",
        "def calculate_vol(net, test_dataloader):\n",
        "    dict_1_preds={}\n",
        "    dict_0_preds={}\n",
        "    dict_1_true={}\n",
        "    dict_0_true={}\n",
        "    dict_2_preds={}\n",
        "    dict_3_preds={}\n",
        "    dict_2_true={}\n",
        "    dict_3_true={}\n",
        " \n",
        "    class_1_volume_pred=0\n",
        "    class_0_volume_pred=0\n",
        "    class_1_volume_true=0\n",
        "    class_0_volume_true=0\n",
        "    class_2_volume_pred=0\n",
        "    class_3_volume_pred=0\n",
        "    class_2_volume_true=0\n",
        "    class_3_volume_true=0\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():  # So no gradients accumulate\n",
        "        for batch_idx, (data, target) in enumerate(test_dataloader):\n",
        "          data = data.to(device).float()\n",
        "          target = target.to(device).float()\n",
        "          pred = net(data)\n",
        "          class_1_volume_pred+=sum_pixels_per_class_batch(pred)[0]\n",
        "          class_0_volume_pred+=sum_pixels_per_class_batch(pred)[1]\n",
        "          class_1_volume_true+=sum_pixels_per_class_batch(target)[0]\n",
        "          class_0_volume_true+=sum_pixels_per_class_batch(target)[1]\n",
        "          class_2_volume_pred+=sum_pixels_per_class_batch(pred)[2]\n",
        "          class_3_volume_pred+=sum_pixels_per_class_batch(pred)[3]\n",
        "          class_2_volume_true+=sum_pixels_per_class_batch(target)[2]\n",
        "          class_3_volume_true+=sum_pixels_per_class_batch(target)[3]\n",
        "          dict_1_preds[batch_idx]=sum_pixels_per_class_batch(pred)[1].cpu().numpy()\n",
        "          dict_0_preds[batch_idx]=sum_pixels_per_class_batch(pred)[0].cpu().numpy()\n",
        "          dict_1_true[batch_idx]=sum_pixels_per_class_batch(target)[1].cpu().numpy()\n",
        "          dict_0_true[batch_idx]=sum_pixels_per_class_batch(target)[0].cpu().numpy()\n",
        "          dict_2_preds[batch_idx]=sum_pixels_per_class_batch(pred)[2].cpu().numpy()\n",
        "          dict_3_preds[batch_idx]=sum_pixels_per_class_batch(pred)[3].cpu().numpy()\n",
        "          dict_2_true[batch_idx]=sum_pixels_per_class_batch(target)[2].cpu().numpy()\n",
        "          dict_3_true[batch_idx]=sum_pixels_per_class_batch(target)[3].cpu().numpy()\n",
        "\n",
        "    return class_1_volume_pred.cpu().numpy(),class_0_volume_pred.cpu().numpy(),class_1_volume_true.cpu().numpy(), class_0_volume_true.cpu().numpy(),class_2_volume_pred.cpu().numpy(),class_3_volume_pred.cpu().numpy(),class_2_volume_true.cpu().numpy(), class_3_volume_true.cpu().numpy()\n",
        "\n",
        "test_dataset = numpy_dataset(X_test_slices, y_test_slices)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=40, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfhlSNFBub1X",
        "outputId": "39f895df-f45f-4204-8da8-6231a22cbed7"
      },
      "outputs": [],
      "source": [
        "# unet\n",
        "class_1_volume_pred,class_0_volume_pred,class_1_volume_true, class_0_volume_true,class_2_volume_pred,class_3_volume_pred,class_2_volume_true, class_3_volume_true = calculate_vol(unet,test_dataloader)\n",
        "print(\"class 1\")\n",
        "print(class_1_volume_pred)\n",
        "print(class_1_volume_true)\n",
        "print(\"class 0\")\n",
        "print(class_0_volume_pred)\n",
        "print(class_0_volume_true)\n",
        "print(\"class 2\")\n",
        "print(class_2_volume_pred)\n",
        "print(class_2_volume_true)\n",
        "print(\"class 3\")\n",
        "print(class_3_volume_pred)\n",
        "print(class_3_volume_true)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
